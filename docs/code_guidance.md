# ğŸš€â€‹ MLOps Code Guidance: The sec-filing-analyzerâ€‹

â€‹This document outlines the official code and project structure for the sec-filing-analyzer.â€‹ â€‹Adhering to this guidance is essential for maintaining a project that isâ€‹â€‹scalable,â€‹ **â€‹reproducible, maintainable, and production-readyâ€‹.â€‹**

## â€‹1. Core Principlesâ€‹

â€‹Our architecture is built on a few key MLOps principles:â€‹

* Separation of Concerns (SoC):â€‹â€‹Every part of the projectâ€‹â€‹has a specific, well-definedâ€‹ â€‹job.â€‹
Training vs. Inference:â€‹â€‹Code forâ€‹â€‹creatingâ€‹â€‹a modelâ€‹â€‹(llm_finetuning/) is separate fromâ€‹ â€‹code forâ€‹â€‹usingâ€‹â€‹a model (src/analysis/).â€‹
â€‹â€‹Code vs. Config:â€‹â€‹Logic (src/) is separate from parametersâ€‹â€‹and settings (configs/).â€‹ â€‹This allows us to change experiments or service endpoints without changing theâ€‹ â€‹code.â€‹
â€‹Data I/O vs. Business Logic:â€‹â€‹ How we connect to a databaseâ€‹ â€‹(src/storage/db_clients.py) is separate fromâ€‹â€‹ what â€‹â€‹we do with that databaseâ€‹ â€‹(src/storage/mongo_repo.py).â€‹
* â€‹Version Everything:â€‹â€‹We version not just our code (Git),â€‹â€‹but also our data (DVC), modelsâ€‹ â€‹(Git LFS or DVC), and database schemas (alembic).â€‹
â€‹* Reproducibility:â€‹â€‹Our Dockerfile, docker-compose.yml,â€‹â€‹and pyproject.toml ensure that â€‹any developer (or CI/CD runner) can create an identical environment and reproduce ourâ€‹ â€‹results.â€‹
* Production First:â€‹â€‹src/ is built as an installableâ€‹â€‹Python package. This enables robustâ€‹ â€‹testing, reusability, and deployment as a service (e.g., API).â€‹

-----

## â€‹2. Directory & File Breakdownâ€‹

### ğŸ“‚â€‹ src/: The Production Code Packageâ€‹

â€‹This is the heart of the application. It is structured as an installable Python package.â€‹
â€‹â—â€‹ â€‹src/acquisition/â€‹: Responsible forâ€‹â€‹gettingâ€‹â€‹data (e.g.,â€‹â€‹edgar_client.py).â€‹
â€‹â—â€‹ â€‹src/preprocessing/â€‹: The "refinery." Responsible forâ€‹â€‹cleaning, parsing, and segmentingâ€‹ â€‹raw data (parser.py, extractor.py, cleaning.py, segmenter.py).â€‹
â€‹â—â€‹ â€‹src/analysis/â€‹: The "brains." Responsible for runningâ€‹â€‹inference with theâ€‹â€‹trainedâ€‹â€‹modelâ€‹ â€‹(inference.py) and deriving value (insights.py).â€‹â€‹Thisâ€‹â€‹code does not train models.â€‹
â€‹â—â€‹ â€‹src/visualization/â€‹: The "face." Responsible for serving â€‹â€‹results, whether as an API (api.py)â€‹ â€‹or a dashboard (app.py).â€‹
â€‹â—â€‹ â€‹src/storage/â€‹: The database "gatekeeper." This is aâ€‹â€‹critical component for abstracting allâ€‹ â€‹data I/O.â€‹
â€‹â—‹â€‹ â€‹schemas/â€‹: Theâ€‹â€‹single source of truthâ€‹â€‹for our data.â€‹â€‹mongo_schemas.py (Pydantic)â€‹ â€‹defines the shape of our "filing index" documents, while postgres_schemas.pyâ€‹ â€‹(SQLAlchemy) defines our "analysis results" tables.â€‹
â€‹â—‹â€‹ â€‹db_clients.pyâ€‹: Handles theâ€‹â€‹howâ€‹â€‹(e.g., creating theâ€‹â€‹connection pool for Postgres,â€‹ â€‹getting the Mongo client). It gets credentials from config.py.â€‹
â€‹â—‹â€‹ â€‹mongo_repo.py / postgres_repo.pyâ€‹: Define theâ€‹â€‹whatâ€‹.â€‹â€‹These files import theâ€‹ â€‹schemas and clients to provide clean, high-level functions for the rest of the appâ€‹ â€‹(e.g., postgres_repo.insert_risk_factor()).â€‹

### ğŸ”¬â€‹ llm_finetuning/â€‹
â€‹This directory holds all scripts, configs, and utilities related toâ€‹â€‹training or fine-tuningâ€‹â€‹ yourâ€‹ â€‹model. It is intentionally separate from src/ because training is an â€‹â€‹experimentationâ€‹â€‹ andâ€‹ _â€‹engineeringâ€‹â€‹task, while inference is aâ€‹â€‹productionâ€‹â€‹task.â€‹_
â€‹â—â€‹ â€‹synthesize_dataset.py: Uses production data (from src.storage.postgres_repo) to build aâ€‹ â€‹new training dataset.â€‹
â€‹â—â€‹ â€‹train.py: The main script to run the fine-tuning job.â€‹
â€‹â—â€‹ â€‹evaluate.py: Script to evaluate a trained model checkpoint.â€‹

-----

### ğŸ”§â€‹ configs/â€‹

â€‹This directory separates all configuration from code.â€‹

â€‹â—â€‹ â€‹data/ & model/â€‹: Holds Hydra-compatible YAMLs for definingâ€‹â€‹datasets and modelâ€‹ â€‹hyperparameters (e.g., learning rate, model name). This allows you to run experimentsâ€‹ â€‹like: python train.py model=llm_base data=finetune_datasetâ€‹
â€‹â—â€‹ â€‹core/services.yamlâ€‹: Defines theâ€‹â€‹infrastructureâ€‹â€‹configuration:â€‹â€‹database URLs, S3 bucketâ€‹ â€‹names, API endpoints. This file defines the â€‹â€‹shape â€‹â€‹of configuration your app expects.â€‹â€‹ Doâ€‹ **â€‹not store secrets here.â€‹â€‹ Secrets are loaded from environmentâ€‹â€‹variables (seeâ€‹ â€‹.env.example).â€‹

### ğŸ—ƒï¸â€‹ data/ & models/â€‹

â€‹These directories areâ€‹â€‹placeholdersâ€‹â€‹for versioned artifacts.â€‹

â€‹â—â€‹ â€‹Git vs. DVC/LFS:â€‹â€‹Git is for code. Large files (data,â€‹â€‹models) are tracked by DVC (metadataâ€‹ â€‹in .dvc/) or Git LFS (pointers in .gitattributes).â€‹
â€‹â—â€‹ â€‹Storage:â€‹â€‹Theâ€‹â€‹actualâ€‹â€‹files live in remote storage (likeâ€‹â€‹S3, MinIO, or a database).â€‹
â€‹â—â€‹ â€‹data/â€‹: Contains small, sample files for testing (data/raw).â€‹â€‹The data/processed folderâ€‹ â€‹might contain a DVC-tracked .jsonl file.â€‹
â€‹â—â€‹ â€‹models/â€‹: The README.md inside this folder should linkâ€‹â€‹to the Hugging Face Hub, S3â€‹ â€‹bucket, or other location where the production model is stored.â€‹

### ğŸ““â€‹ notebooks/â€‹

â€‹Notebooks are forâ€‹â€‹exploration, prototyping, and analysisâ€‹â€”notâ€‹â€‹ production.â€‹

â€‹â—â€‹ â€‹Naming:â€‹â€‹Use a numbered prefix (e.g., 01_data_exploration.ipynb)â€‹â€‹to tell a story.â€‹
â€‹â—â€‹ â€‹The "Notebook to Production" Workflow:â€‹
â€‹1.â€‹ â€‹Prototype:â€‹â€‹Develop your logic (e.g., a new regex forâ€‹â€‹extractor.py) inâ€‹ â€‹02_preprocessing_dev.ipynb.â€‹
â€‹2.â€‹ â€‹Refactor:â€‹â€‹Once the logic is stable, copy it into theâ€‹â€‹ appropriate .py file inâ€‹ â€‹src/preprocessing/.â€‹
â€‹3.â€‹ â€‹Test:â€‹â€‹ Write a formal unit test for your new functionâ€‹â€‹in tests/test_preprocessing.py.â€‹
â€‹4.â€‹ â€‹Commit:â€‹â€‹Your notebook (with its outputs) can be committed as a record of theâ€‹ â€‹experiment, but theâ€‹â€‹production logicâ€‹â€‹now lives inâ€‹â€‹ src/ and is covered by tests.â€‹

### ğŸ›ï¸â€‹ alembic/ & alembic.iniâ€‹

â€‹This is ourâ€‹â€‹database schema version controlâ€‹. Justâ€‹â€‹as we use Git to manage changes to ourâ€‹
â€‹code, we use Alembic to manage changes to our Postgres database schema.â€‹

â€‹â—â€‹ â€‹alembic/versions/â€‹: Contains migration scripts (e.g.,â€‹â€‹001_add_risk_table.py).â€‹
â€‹â—â€‹ â€‹Makefile Commands:â€‹

â€‹â—‹â€‹ â€‹make db-migration M="your message": Auto-generates a new migration script basedâ€‹ â€‹on changes in src/storage/schemas/postgres_schemas.py.â€‹
â€‹â—‹â€‹ â€‹make db-upgrade: Applies any pending migrations to the database.â€‹

## â€‹3. Key Workflows in Practiceâ€‹

### â€‹Workflow: Data Ingestion & Preprocessingâ€‹

â€‹This example shows how the src/ modules work together as a pipeline.â€‹

â€‹1.â€‹ â€‹Orchestrator (main.py)â€‹: Gets its work queue by callingâ€‹ â€‹src.storage.mongo_repo.get_filings_to_process().â€‹
â€‹2.â€‹ â€‹Fetch Dataâ€‹: For a given filing, it fetches the rawâ€‹â€‹HTML from S3/MinIO.â€‹
â€‹3.â€‹ â€‹Parse (parser.py)â€‹: The raw HTML is passed to parser.parse_filing().â€‹
â€‹4.â€‹ â€‹Extract (extractor.py)â€‹: The parsed object is passedâ€‹â€‹to extractor.find_risk_section() toâ€‹ â€‹get the specific HTML blob.â€‹
â€‹5.â€‹ â€‹Clean (cleaning.py)â€‹: The blob is passed to cleaning.clean_html_blob()â€‹â€‹to get clean text.â€‹
â€‹6.â€‹ â€‹Segment (segmenter.py)â€‹: The clean text is passed toâ€‹â€‹segmenter.split_into_risks() to getâ€‹ â€‹a list[str].â€‹
â€‹7.â€‹ â€‹Analyze (analysis/inference.py)â€‹: This list is passedâ€‹â€‹to the analysis engine, which loadsâ€‹ â€‹the fine-tuned model and generates embeddings and categories for each risk.â€‹
â€‹8.â€‹ â€‹Save Results (storage/postgres_repo.py)â€‹: The pipelineâ€‹â€‹callsâ€‹ â€‹postgres_repo.insert_risk_factor() for each processed risk, saving the text, embedding,â€‹ â€‹and category to Postgres.â€‹
â€‹9.â€‹ â€‹Update Status (storage/mongo_repo.py)â€‹: The pipelineâ€‹â€‹callsâ€‹ â€‹mongo_repo.update_filing_status() to mark the filing as "processed" in MongoDB.â€‹

â€‹This modular structure allows each step to be tested, updated, and even run as a separateâ€‹ â€‹microservice.â€‹

