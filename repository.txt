# SEC Filing Analyzer - Repository Structure
# Updated: 2025-12-28
#
# GUIDANCE:
# - All code must use Pydantic v2.12.4+ (enforced by validation script)
# - Configuration uses YAML files in configs/ with Pydantic Settings
# - Scripts organized by ML lifecycle stages (01-10)
# - Use pyproject.toml for dependency management (no requirements.txt)
# - Run validation before commits: python scripts/utils/validation/validate_pydantic_v2.py

sec-filing-analyzer/
‚îÇ
‚îú‚îÄ‚îÄ .git/                   # Git version control
‚îú‚îÄ‚îÄ .gitignore              # Ignores data/, logs/, venv/, model checkpoints
‚îÇ
‚îú‚îÄ‚îÄ README.md               # Project overview, setup, usage
‚îú‚îÄ‚îÄ pyproject.toml          # Project metadata, dependencies (Pydantic >=2.12.4)
‚îú‚îÄ‚îÄ repository.txt          # This file - repository structure reference
‚îÇ
‚îú‚îÄ‚îÄ configs/                # YAML configuration files (Pydantic Settings)
‚îÇ   ‚îú‚îÄ‚îÄ README.md           # Configuration system documentation
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml         # Main application configuration
‚îÇ   ‚îî‚îÄ‚îÄ features/
‚îÇ       ‚îú‚îÄ‚îÄ sentiment.yaml  # Sentiment analysis configuration
‚îÇ       ‚îú‚îÄ‚îÄ readability.yaml # Readability/complexity analysis configuration
‚îÇ       ‚îú‚îÄ‚îÄ topic_modeling.yaml # LDA model configuration
‚îÇ       ‚îî‚îÄ‚îÄ risk_analysis.yaml  # ‚ö†Ô∏è Risk analysis (Auto-labeling & Drift) configuration
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Data directory (versioned by DVC, not in Git)
‚îÇ   ‚îú‚îÄ‚îÄ dictionary/         # Reference dictionaries (e.g., Loughran-McDonald)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Original SEC filings (HTML/XBRL)
‚îÇ   ‚îú‚îÄ‚îÄ interim/            # Intermediate processed data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parsed/         # Parsed SEC filings (JSON)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extracted/      # Extracted sections
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # Final datasets ready for modeling
‚îÇ       ‚îú‚îÄ‚îÄ labeled/        # ‚ö†Ô∏è Auto-labeled training datasets (Versioned by RunContext)
‚îÇ       ‚îî‚îÄ‚îÄ features/       # Extracted features (sentiment, readability, embeddings)
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Project documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md           # Documentation index with Pydantic v2 quick start
‚îÇ   ‚îú‚îÄ‚îÄ PYDANTIC_V2_ENFORCEMENT.md  # ‚ö†Ô∏è REQUIRED: Pydantic v2 enforcement guide
‚îÇ   ‚îú‚îÄ‚îÄ ENUM_CONFIG_PATTERNS.md     # Configuration patterns (Pydantic v2)
‚îÇ   ‚îú‚îÄ‚îÄ CONFIG_MIGRATION_GUIDE.md   # Configuration migration guide
‚îÇ   ‚îî‚îÄ‚îÄ requirements/       # Historical requirements (reference only)
‚îÇ
‚îú‚îÄ‚îÄ examples/               # Example scripts demonstrating usage
‚îÇ   ‚îú‚îÄ‚îÄ 01_basic_extraction.py              # Basic section extraction
‚îÇ   ‚îú‚îÄ‚îÄ 02_complete_pipeline.py             # Full pipeline example
‚îÇ   ‚îú‚îÄ‚îÄ 03_sentiment_analysis.py            # Sentiment analysis example
‚îÇ   ‚îî‚îÄ‚îÄ 04_sentiment_risk_classification.py # Risk classification example
‚îÇ
‚îú‚îÄ‚îÄ logs/                   # Application logs (not in Git)
‚îÇ   ‚îî‚îÄ‚îÄ extractions/        # Extraction process logs
‚îÇ
‚îú‚îÄ‚îÄ models/                 # Trained models (tracked by Git LFS or DVC)
‚îÇ   ‚îú‚îÄ‚îÄ experiments/        # ‚ö†Ô∏è Training experiments (checkpoints, logs)
‚îÇ   ‚îú‚îÄ‚îÄ registry/           # ‚ö†Ô∏è Production-ready models
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Model storage and versioning info
‚îÇ
‚îú‚îÄ‚îÄ reports/                # Generated analysis and visualizations
‚îÇ
‚îú‚îÄ‚îÄ scripts/                # ML lifecycle scripts (numbered by stage)
‚îÇ   ‚îú‚îÄ‚îÄ README.md           # Scripts directory overview
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_collection/         # Stage 1: Data acquisition
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ download_sec_filings.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_preprocessing/      # Stage 2: Parsing and extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch_parse.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_preprocessing_pipeline.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 03_eda/                     # Stage 3: Exploratory data analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exploratory_analysis.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 04_feature_engineering/     # Stage 4: Feature extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract_features.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto_label.py           # ‚ö†Ô∏è Teacher-Student auto-labeling pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detect_drift.py         # ‚ö†Ô∏è Topic drift detection (Year-over-Year)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ topic_modeling_demo.py  # LDA demo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ preprocess_lm_dict.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 05_data_splitting/          # Stage 5: Train/test splits
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ create_train_test_split.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 06_training/                # Stage 6: Model training
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 07_evaluation/              # Stage 7: Model evaluation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate_model.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 08_inference/               # Stage 8: Predictions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ 09_deployment/              # Stage 9: Deployment (placeholder)
‚îÇ   ‚îú‚îÄ‚îÄ 10_monitoring/              # Stage 10: Monitoring (placeholder)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                      # Development utilities
‚îÇ       ‚îú‚îÄ‚îÄ README.md               # Utilities documentation
‚îÇ       ‚îú‚îÄ‚îÄ check_installation.py  # Verify environment setup
‚îÇ       ‚îú‚îÄ‚îÄ setup_nlp_models.py    # Download NLP models
‚îÇ       ‚îú‚îÄ‚îÄ show_segment_sample.py # Display data samples
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ debugging/              # Debug tools
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ diagnose_extraction.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ debug_node_structure.py
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ inspection/             # Data inspection tools
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ inspect_parsed.py
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ testing/                # Testing utilities
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ test_extractor_fix.py
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ validation/             # ‚ö†Ô∏è Code quality validation
‚îÇ           ‚îú‚îÄ‚îÄ README.md
‚îÇ           ‚îî‚îÄ‚îÄ validate_pydantic_v2.py  # Pydantic v2 enforcement
‚îÇ
‚îú‚îÄ‚îÄ src/                    # Main source code (importable Python package)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/             # ‚ö†Ô∏è Configuration Subsystem (Pydantic Settings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py     # Exports PipelineConfig, RunContext
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_context.py  # ‚ö†Ô∏è RunContext (Versioned output management)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qa_validation.py # ‚ö†Ô∏è Data Quality & Validation Config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naming.py       # Naming conventions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/      # SEC filing parsing and extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaning.py     # Text cleaning (spaCy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.py       # Parse HTML/XBRL filings (sec-parser)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segmenter.py    # ‚ö†Ô∏è Semantic chunking (SentenceTransformers)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extractor.py    # Extract specific sections (Item 1A, etc.)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/           # Feature engineering modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment.py    # Sentiment analysis with LM dictionary
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dictionaries/   # Dictionary-based features
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constants.py        # Feature category definitions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lm_dictionary.py    # Loughran-McDonald dictionary
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # ‚ö†Ô∏è Pydantic v2 data models (3 models)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ readability/    # Text complexity & readability analysis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constants.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyzer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ topic_modeling/ # ‚ö†Ô∏è LDA Topic Modeling
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ analyzer.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ constants.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ lda_trainer.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis/           # NLP analysis and inference
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py    # Model inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ taxonomies/     # ‚ö†Ô∏è Taxonomy Management
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ risk_taxonomy.yaml      # Base taxonomy
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sasb_sics_mapping.json  # ‚ö†Ô∏è SIC -> SASB Industry Map
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ taxonomy_manager.py     # ‚ö†Ô∏è TaxonomyManager (Pydantic V2)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/              # Shared utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state_manager.py # ‚ö†Ô∏è MLOps: StateManifest & Atomic Writes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporting.py     # ‚ö†Ô∏è MLOps: Markdown Reporting & Audit Trails
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ visualization/      # Visualization and UI
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ app.py          # Streamlit dashboard
‚îÇ
‚îî‚îÄ‚îÄ tests/                  # Unit and integration tests
    ‚îú‚îÄ‚îÄ __init__.py         # Test package initialization
    ‚îú‚îÄ‚îÄ conftest.py         # Shared pytest fixtures
    ‚îú‚îÄ‚îÄ test_cleaning.py    # Legacy cleaning tests (run standalone)
    ‚îÇ
    ‚îî‚îÄ‚îÄ preprocessing/      # Preprocessing module tests
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ test_parser_section_recall.py  # ‚ö†Ô∏è Key Section Recall QA tests
                                           # Metrics: recall, latency, idempotency


# ========================================
# KEY CONCEPTS & GUIDANCE
# ========================================

## 1. PYDANTIC V2 ENFORCEMENT (MANDATORY)
#
# ‚ö†Ô∏è ALL CODE MUST USE PYDANTIC V2.12.4+
#
# Before committing:
#   python scripts/utils/validation/validate_pydantic_v2.py src/
#
# See docs/PYDANTIC_V2_ENFORCEMENT.md for complete guide
# See docs/README.md for quick reference
#
# Quick Reference:
#   ‚ùå NEVER USE: @validator, class Config:, .dict(), .json()
#   ‚úÖ ALWAYS USE: @field_validator, model_config =, .model_dump(), .model_dump_json()

## 2. CONFIGURATION MANAGEMENT
#
# The project uses a multi-layer configuration system:
#
# Layer 1: YAML Defaults
#   - configs/config.yaml (main settings)
#   - configs/features/sentiment.yaml (sentiment analysis)
#   - configs/features/readability.yaml (readability/complexity)
#   - configs/features/topic_modeling.yaml (LDA parameters)
#   - configs/features/risk_analysis.yaml (drift threshold, auto-label model)
#
# Layer 2: Pydantic Settings Models (src/config.py)
#   - Type-safe with validation (RiskAnalysisConfig, TopicModelingConfig)
#   - Environment variable support with prefixes
#   - Includes RunContext for versioned output management
#
# Layer 3: Environment Variables (.env)
#   - Override YAML defaults at runtime
#   - Use env_prefix for namespacing (e.g., PATHS_*, SENTIMENT_*)
#
# Layer 4: Legacy Exports (backward compatibility)
#   - Module-level variables for easy imports
#
# See docs/ENUM_CONFIG_PATTERNS.md for patterns
# See docs/CONFIG_MIGRATION_GUIDE.md for migration

## 3. READABILITY ANALYSIS (TEXT COMPLEXITY AS RISK PROXY)
#
# The readability module measures text complexity in SEC filings.
# Research shows harder-to-read 10-Ks are associated with:
#   - Higher future stock volatility
#   - More negative earnings surprises
#   - Higher audit fees
#   - Potential obfuscation of bad news
#
# Key Components:
#
# 1. Standard Readability Indices (via textstat library):
#   - Flesch-Kincaid Grade Level (most widely used in research)
#   - Gunning Fog Index (better for business/technical writing)
#   - Flesch Reading Ease (0-100 scale)
#   - SMOG Index, ARI, Coleman-Liau Index
#
# 2. Financial Domain Adjustments:
#   - FINANCIAL_COMMON_WORDS: 200+ curated 3+ syllable terms
#   - Excludes common financial words from "complex word" count
#   - Examples excluded: investment, management, financial, regulatory
#   - Impact: Reduces false positives by 35-50% for 10-Ks
#
# 3. Custom Obfuscation Score (0-100):
#   - Weighted composite of multiple readability signals
#   - <40: Clear, 40-60: Typical 10-K, 60-75: Elevated, >75: High risk
#   - Combines FK grade, Fog index, sentence length, complex words
#
# 4. Structural Complexity Metrics:
#   - Average sentence length, word length, syllables per word
#   - Percentage of long sentences (>30 words)
#   - Paragraph length analysis
#
# Module Structure (follows dictionaries/ pattern):
#   - constants.py: Immutable (financial word list, benchmarks, citations)
#   - schemas.py: Pydantic v2 models (ReadabilityFeatures, Metadata, Result)
#   - analyzer.py: ReadabilityAnalyzer class (textstat + adjustments)
#
# Usage:
#   from src.features import ReadabilityAnalyzer
#   from src.preprocessing.cleaning import TextCleaner
#
#   cleaner = TextCleaner(remove_punctuation=False)  # Keep for sentences!
#   cleaned = cleaner.clean_html_text(raw_text)
#
#   analyzer = ReadabilityAnalyzer()
#   features = analyzer.extract_features(cleaned)
#   print(f"Gunning Fog: {features.gunning_fog_index}")
#   print(f"Obfuscation Score: {features.obfuscation_score}/100")
#
# Academic References:
#   - Li (2008): Annual report readability and earnings persistence
#   - Loughran & McDonald (2014): Measuring readability in financial disclosures

## 4. PROJECT STRUCTURE PHILOSOPHY
#
# Separation of Concerns:
#   src/          - Production code (clean, tested, importable)
#   scripts/      - Pipeline execution (numbered by ML stage)
#   examples/     - Demonstration and learning
#   tests/        - Quality assurance
#
# Data Organization:
#   raw/          - Original, immutable data
#   interim/      - Intermediate transformations
#   processed/    - Final, model-ready datasets
#
# Scripts Organization (ML Lifecycle):
#   01-10 prefix  - Natural execution order
#   utils/        - Cross-cutting tools (debugging, validation, testing)

## 5. DEVELOPMENT WORKFLOW
#
# 1. Setup:
#    git clone https://github.com/bethCoderNewbie/SEC-finetune.git
#    cd SEC-finetune
#    pip install -e ".[dev]"
#    python scripts/utils/setup_nlp_models.py
#
# 2. Before Coding:
#    - Review docs/PYDANTIC_V2_ENFORCEMENT.md
#    - Check existing patterns in src/config.py and src/features/dictionaries/schemas.py
#
# 3. During Development:
#    - Use Pydantic v2 patterns only
#    - Add type hints to all functions
#    - Document with docstrings
#
# 4. Before Committing:
#    python scripts/utils/validation/validate_pydantic_v2.py <your_files>
#    ruff check src/ scripts/
#    mypy src/
#
# 5. Commit:
#    git add <files>
#    git commit -m "Description"
#    git push

## 6. IMPORTANT FILES
#
# Configuration:
#   - src/config.py              (21 Pydantic Settings models)
#   - configs/config.yaml        (YAML defaults)
#   - configs/features/sentiment.yaml
#   - configs/features/readability.yaml
#
# Data Models:
#   - src/features/dictionaries/schemas.py  (3 Pydantic data models)
#   - src/features/readability/schemas.py   (3 Pydantic data models)
#
# Validation:
#   - scripts/utils/validation/validate_pydantic_v2.py
#
# Documentation:
#   - docs/PYDANTIC_V2_ENFORCEMENT.md  (enforcement guide)
#   - docs/README.md                    (documentation index)
#   - docs/ENUM_CONFIG_PATTERNS.md     (configuration patterns)

## 7. DEPENDENCY MANAGEMENT
#
# ‚úÖ USE: pyproject.toml (modern, PEP 621 compliant)
# ‚ùå NEVER: requirements.txt, requirements-dev.txt (removed)
#
# Install:
#   pip install -e .              # Base dependencies
#   pip install -e ".[dev]"       # With dev tools (ruff, mypy, pytest)
#   pip install -e ".[all]"       # Everything
#
# Key Dependencies:
#   - pydantic>=2.12.4           # ENFORCED
#   - pydantic-settings>=2.0.0   # For configuration
#   - sec-parser==0.54.0         # SEC filing parsing
#   - transformers>=4.35.0       # NLP models
#   - streamlit>=1.28.0          # Visualization
#   - textstat>=0.7.0            # Readability metrics

## 8. ML PIPELINE STAGES
#
# 01: Data Collection    ‚Üí Download SEC filings from EDGAR
# 02: Preprocessing      ‚Üí Parse HTML, extract sections
# 03: EDA               ‚Üí Exploratory data analysis
# 04: Feature Engineering ‚Üí Extract sentiment, readability, embeddings
# 05: Data Splitting    ‚Üí Create train/val/test splits
# 06: Training          ‚Üí Train/fine-tune models
# 07: Evaluation        ‚Üí Calculate metrics
# 08: Inference         ‚Üí Run predictions
# 09: Deployment        ‚Üí Deploy to production (planned)
# 10: Monitoring        ‚Üí Monitor performance (planned)

## 9. CODE QUALITY STANDARDS
#
# Enforced:
#   - Pydantic v2.12.4+ (automated validation)
#   - Type hints (mypy checking)
#   - Code formatting (black, ruff)
#   - Docstrings (all public functions)
#
# Pre-commit Checks:
#   - Pydantic v2 validation
#   - Ruff linting
#   - MyPy type checking
#   - Pytest (when available)

## 10. TESTING & QA

# Test Suite Structure:
#   tests/
#   ‚îú‚îÄ‚îÄ conftest.py                           # Shared fixtures (parser, paths, sample data)
#   ‚îî‚îÄ‚îÄ preprocessing/
#       ‚îî‚îÄ‚îÄ test_parser_section_recall.py     # Parser QA tests
#
# Running Tests:
#   # Run all tests
#   pytest tests/ -v
#
#   # Run parser QA tests with output
#   pytest tests/preprocessing/test_parser_section_recall.py -v -s
#
#   # Run specific test class
#   pytest tests/preprocessing/test_parser_section_recall.py::TestParserSectionRecall -v
#
#   # Generate coverage report
#   pytest tests/ --cov=src --cov-report=html
#
#   # Generate metrics report
#   pytest tests/preprocessing/test_parser_section_recall.py::TestMetricsReport -v -s
#
# Key QA Metrics (from qa.md):
#   - Key Section Recall: > 99% (Item 1, 1A, 7, 7A for 10-K)
#   - Parsing Latency: < 5 seconds per document
#   - Idempotency: Same file = identical output
#   - Error Rate: < 1% parse failures
#
# Test Markers:
#   @pytest.mark.slow          - Long-running tests
#   @pytest.mark.integration   - End-to-end tests
#   pytest -m "not slow" ...   - Skip slow tests

## 11. CURRENT PROJECT STATUS
#
# ‚úÖ Complete:
#   - Pydantic v2 enforcement system
#   - Configuration refactor to YAML + Pydantic Settings
#   - Sentiment analysis with Loughran-McDonald dictionary
#   - Readability/complexity analysis with financial domain adjustments
#   - Text cleaning pipeline (TextCleaner with HTML/boilerplate removal)
#   - Feature extraction pipeline (sentiment + readability integrated)
#   - Validation automation
#   - Comprehensive documentation
#
# üöß In Progress:
#   - Model training infrastructure
#   - Evaluation metrics
#
# üìã Planned:
#   - Deployment automation
#   - Monitoring dashboards
#   - CI/CD pipelines

## 11. GETTING HELP
#
# Documentation:
#   - docs/README.md                    - Start here
#   - docs/PYDANTIC_V2_ENFORCEMENT.md  - Pydantic v2 guide
#   - scripts/utils/README.md          - Utility scripts
#   - scripts/README.md                - ML pipeline scripts
#
# Validation:
#   python scripts/utils/validation/validate_pydantic_v2.py --help
#
# Examples:
#   - examples/01_basic_extraction.py
#   - examples/03_sentiment_analysis.py
#
# Debugging:
#   - scripts/utils/debugging/diagnose_extraction.py
#   - scripts/utils/inspection/inspect_parsed.py

# ========================================
# END OF REPOSITORY STRUCTURE
# ========================================